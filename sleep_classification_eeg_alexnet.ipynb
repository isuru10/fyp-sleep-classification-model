{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.loadtxt('../ISRUC-Sleep Dataset/Two Session Subjects/Subject 1/1/1_1.txt')[:-30]\n",
    "np.place(labels, labels==5, [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'eeg_images'\n",
    "onlyfiles = [f for f in os.listdir(rootdir) if os.path.isfile(os.path.join(rootdir, f))]\n",
    "\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train_files = []\n",
    "y_train = labels\n",
    "\n",
    "i=0\n",
    "\n",
    "for _file in onlyfiles:\n",
    "    train_files.append(_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "dataset = np.ndarray(shape=(len(train_files), 288, 432, 3), dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for _file in train_files:\n",
    "    img = load_img(rootdir + \"/\" + _file)\n",
    "    img.thumbnail((432, 288))\n",
    "    x = img_to_array(img) \n",
    "    x = (x - 128.0) / 128.0\n",
    "    dataset[i] = x\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=0.1, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0106 13:03:16.731564 139823258576704 deprecation.py:506] From /home/isuru/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 70, 106, 96)       34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 70, 106, 96)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 35, 53, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 43, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 43, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 21, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 19, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10, 19, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 17, 384)        1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 17, 384)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 15, 256)        884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 15, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              22024192  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                17017     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 49,026,017\n",
      "Trainable params: 49,026,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "\n",
    "np.random.seed(1000)\n",
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(288,432,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(17))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 812 samples, validate on 91 samples\n",
      "Epoch 1/8\n",
      "812/812 [==============================] - 346s 426ms/sample - loss: 1.9991 - acc: 0.2303 - val_loss: 1.6394 - val_acc: 0.2527\n",
      "Epoch 2/8\n",
      "812/812 [==============================] - 374s 460ms/sample - loss: 1.6268 - acc: 0.2475 - val_loss: 1.6268 - val_acc: 0.2088\n",
      "Epoch 3/8\n",
      "812/812 [==============================] - 327s 403ms/sample - loss: 1.6158 - acc: 0.2328 - val_loss: 1.6147 - val_acc: 0.2088\n",
      "Epoch 4/8\n",
      "812/812 [==============================] - 350s 431ms/sample - loss: 1.6041 - acc: 0.2315 - val_loss: 1.6008 - val_acc: 0.2527\n",
      "Epoch 5/8\n",
      "566/812 [===================>..........] - ETA: 1:38 - loss: 1.6038 - acc: 0.2350"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=2,\n",
    "          epochs=8,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
